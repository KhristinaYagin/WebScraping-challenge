We collected data from websites via web scraping techniques. First, learned about how websites are made by using HTML and CSS. We build simple websites to make sure that  we understand how HTML and CSS work together to design the content and style of web pages. Then, we used your knowledge of HTML and CSS, alongside the Python package Beautiful Soup, to extract specific information from HTML code.

Once we have developed our web scraping skills, we took them even further by scraping real websites. Used the automated browsing package Splinter to extract and store data from multiple pages of the same website.
In addition, you will use the following tools to explore and scrape websites:

> Splinter, a tool that automates our web browser actions, which allows us to automatically scan and repeat interactions on websites.

> ChromeDriver, which enables automation in the Chrome browser.

> Beautiful Soup, a Python library that allows you to pull out and parse specific information from a webpage.

> html5lib and lxml, which are packages that Beautiful Soup uses to parse websites.
